{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobiles-dataset-2025 downloaded\n"
     ]
    }
   ],
   "source": [
    "#file_reading\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "urls = ['https://www.kaggle.com/datasets/abdulmalik1518/mobiles-dataset-2025']\n",
    "\n",
    "def download_file(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"{filename} downloaded\")\n",
    "\n",
    "# Multithreading to download files\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(download_file, urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netflix-movies-and-tv-shows downloaded\n",
      "datascience-job-data downloaded\n",
      "hr-analytics-dataset downloaded\n"
     ]
    }
   ],
   "source": [
    "#multithreading to download multiple files simultaneously.\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "urls = [\n",
    "    'https://www.kaggle.com/datasets/anandshaw2001/netflix-movies-and-tv-shows',\n",
    "    'https://www.kaggle.com/datasets/sachinkumar62/datascience-job-data',\n",
    "    'https://www.kaggle.com/datasets/hopesb/hr-analytics-dataset'\n",
    "]\n",
    "\n",
    "def download_file(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"{filename} downloaded\")\n",
    "\n",
    "# Multithreading to download files\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(download_file, urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocessing script to compute the factorial of numbers from 1 to 10.\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to multiply row values by 2\n",
    "def multiply_row(row_dict):\n",
    "    for key in row_dict:\n",
    "        row_dict[key] *= 2\n",
    "    return row_dict\n",
    "\n",
    "# Process DataFrame in parallel\n",
    "def process_dataframe(df):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        modified_rows = list(executor.map(multiply_row, df.to_dict(orient='records')))\n",
    "    return pd.Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify a Pandas dataframe in parallel using concurrent.futures\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to multiply values in a row dictionary\n",
    "def multiply_row(row_dict):\n",
    "    return {key: value * 2 for key, value in row_dict.items()}\n",
    "\n",
    "# Function to process DataFrame in parallel\n",
    "def process_dataframe(df):\n",
    "    rows = df.to_dict(orient='records')  # Convert rows to list o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 4...\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#Decorator that caches results for function calls\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def expensive_computation(x):\n",
    "    print(f\"Computing {x}...\")\n",
    "    return x * x\n",
    "\n",
    "print(expensive_computation(4))\n",
    "print(expensive_computation(4))  # Cached result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Random failure occurred\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "#retry decorator that retries a function call 3 times if it fails\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def retry(times=3):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(times):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "                    time.sleep(1)\n",
    "            print(\"All attempts failed.\")\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry(times=3)\n",
    "def unreliable_function():\n",
    "    import random\n",
    "    if random.random() < 0.7:\n",
    "        raise ValueError(\"Random failure occurred\")\n",
    "    return \"Success!\"\n",
    "\n",
    "print(unreliable_function())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
